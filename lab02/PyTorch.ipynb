{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch æœ‰ä½•ä¸šåŠ¡ï¼Ÿ\n",
    "\n",
    "åœ¨æœ¬è¯¾ä¹‹å‰çš„å­¦ä¹ å½“ä¸­ï¼Œæˆ‘ä»¬å·²ç»ç¼–å†™äº†å¤§é‡ä»£ç æ¥å®Œæˆä¸€å¥—ç¥ç»ç½‘ç»œåŠŸèƒ½ã€‚Dropoutã€Batch Norm å’Œ 2D å·ç§¯æ˜¯è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ çš„ä¸€äº›ä¸»åŠ›ã€‚æˆ‘ä»¬è¿˜åŠªåŠ›ä½¿ä»£ç é«˜æ•ˆä¸”çŸ¢é‡åŒ–ã€‚\n",
    "\n",
    "ä¸è¿‡ï¼Œå¯¹äºæœ¬æ¬¡ä½œä¸šçš„åä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ”¾å¼ƒæ‚¨æ¼‚äº®çš„ä»£ç åº“ï¼Œè€Œæ˜¯è¿ç§»åˆ°ä¸¤ä¸ªæµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¹‹ä¸€ï¼šåœ¨æœ¬ä¾‹ä¸­ï¼Œæ˜¯ PyTorchï¼ˆæˆ– TensorFlowï¼Œå¦‚æœæ‚¨åˆ‡æ¢åˆ°è¯¥Jupyter Notebookï¼‰ã€‚ \n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ PyTorch?\n",
    "\n",
    "PyTorch æ˜¯ä¸€ä¸ªç”¨äºåœ¨ Tensor å¯¹è±¡ä¸Šæ‰§è¡ŒåŠ¨æ€è®¡ç®—å›¾çš„ç³»ç»Ÿï¼Œå…¶è¡Œä¸ºä¸ Numpy Ndarray ç±»ä¼¼ã€‚å®ƒé…å¤‡äº†å¼ºå¤§çš„è‡ªåŠ¨å¾®åˆ†å¼•æ“ï¼Œæ— éœ€æ‰‹åŠ¨åå‘ä¼ æ’­ã€‚\n",
    "\n",
    "### ä¸ºä»€ä¹ˆç”¨PyTorch?\n",
    "\n",
    "* æˆ‘ä»¬çš„ä»£ç ç°åœ¨å°†åœ¨ GPU ä¸Šè¿è¡Œï¼è®­ç»ƒé€Ÿåº¦æ›´å¿«ã€‚ä½¿ç”¨ PyTorch æˆ– TensorFlow ç­‰æ¡†æ¶æ—¶ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ GPU çš„å¼ºå¤§åŠŸèƒ½æ¥å®ç°æ‚¨è‡ªå·±çš„è‡ªå®šä¹‰ç¥ç»ç½‘ç»œæ¶æ„ï¼Œè€Œæ— éœ€ç›´æ¥ç¼–å†™ CUDA ä»£ç ï¼ˆè¿™è¶…å‡ºäº†æœ¬è¯¾ç¨‹çš„èŒƒå›´ï¼‰ã€‚\n",
    "* æˆ‘ä»¬å¸Œæœ›æ‚¨å‡†å¤‡å¥½åœ¨æ‚¨çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™äº›æ¡†æ¶ä¹‹ä¸€ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥æ¯”æ‰‹åŠ¨ç¼–å†™è¦ä½¿ç”¨çš„æ¯ä¸ªåŠŸèƒ½æ›´æœ‰æ•ˆåœ°è¿›è¡Œå®éªŒã€‚\n",
    "* æˆ‘ä»¬å¸Œæœ›ä½ ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼ TensorFlow å’Œ PyTorch éƒ½æ˜¯ä¼˜ç§€çš„æ¡†æ¶ï¼Œå¯ä»¥è®©æ‚¨çš„ç”Ÿæ´»å˜å¾—æ›´åŠ è½»æ¾ï¼Œç°åœ¨æ‚¨äº†è§£äº†å®ƒä»¬çš„æœ¬è´¨ï¼Œå°±å¯ä»¥è‡ªç”±ä½¿ç”¨å®ƒä»¬äº†ğŸ™‚\n",
    "* æˆ‘ä»¬å¸Œæœ›æ‚¨èƒ½å¤Ÿæ¥è§¦åˆ°åœ¨å­¦æœ¯ç•Œæˆ–å·¥ä¸šç•Œå¯èƒ½é‡åˆ°çš„æ·±åº¦å­¦ä¹ ä»£ç ã€‚\n",
    "\n",
    "### PyTorch ç‰ˆæœ¬\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬å‡è®¾æ‚¨ä½¿ç”¨ **PyTorch 0.4 ç‰ˆæœ¬**.åœ¨æ­¤ç‰ˆæœ¬ä¹‹å‰ï¼Œå¼ é‡å¿…é¡»åŒ…è£…åœ¨ Variable å¯¹è±¡ä¸­æ‰èƒ½åœ¨ Autograd ä¸­ä½¿ç”¨ï¼›ç„¶è€Œï¼Œå˜é‡ç°åœ¨å·²è¢«å¼ƒç”¨ã€‚æ­¤å¤–ï¼Œ0.4 è¿˜å°† Tensor çš„æ•°æ®ç±»å‹ä¸å…¶è®¾å¤‡åˆ†ç¦»ï¼Œå¹¶ä½¿ç”¨ Numpy é£æ ¼çš„å·¥å‚æ¥æ„é€  Tensorï¼Œè€Œä¸æ˜¯ç›´æ¥è°ƒç”¨ Tensor æ„é€ å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æˆ‘ä»¬å°†å¦‚ä½•å­¦ä¹  PyTorch?\n",
    "\n",
    "Justin Johnson ä¸ºPyTorchåšäº†æ°å‡ºè´¡çŒ®[æ•™ç¨‹](https://github.com/jcjohnson/pytorch-examples)ã€‚\n",
    "\n",
    "ä½ è¿˜å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°è¯¦ç»†çš„[APIæ–‡æ¡£](http://pytorch.org/docs/stable/index.html) ã€‚ å¦‚æœæ‚¨æœ‰ API æ–‡æ¡£æœªè§£å†³çš„å…¶ä»–é—®é¢˜,[PyTorch forum](https://discuss.pytorch.org/) æ˜¯ä¸€ä¸ªæ¯” StackOverflow æ›´å¥½çš„æé—®åœ°ç‚¹ã€‚\n",
    "\n",
    "\n",
    "# ç›®å½•\n",
    "\n",
    "æœ¬ä½œä¸šæœ‰ 5 ä¸ªéƒ¨åˆ†ã€‚æ‚¨å°†åœ¨ä¸åŒçš„æŠ½è±¡çº§åˆ«ä¸Šå­¦ä¹  PyTorchï¼Œè¿™å°†å¸®åŠ©æ‚¨æ›´å¥½åœ°ç†è§£å®ƒå¹¶ä¸ºæœ€ç»ˆé¡¹ç›®åšå¥½å‡†å¤‡ã€‚\n",
    "\n",
    "1. å‡†å¤‡å·¥ä½œ: æˆ‘ä»¬å°†ä½¿ç”¨ CIFAR-10 æ•°æ®é›†.\n",
    "2. Barebons PyTorch: æˆ‘ä»¬å°†ç›´æ¥ä½¿ç”¨æœ€ä½çº§åˆ«çš„ PyTorch å¼ é‡ã€‚ \n",
    "3. PyTorch Module API: æˆ‘ä»¬å°†ä½¿ç”¨ `nn.Module` æ¥å®šä¹‰ä»»æ„ç¥ç»ç½‘ç»œæ¶æ„ã€‚\n",
    "4. PyTorch Sequential API: æˆ‘ä»¬å°†ä½¿ç”¨ `nn.Sequential` éå¸¸æ–¹ä¾¿åœ°å®šä¹‰çº¿æ€§å‰é¦ˆç½‘ç»œã€‚\n",
    "5. CIFAR-10 å¼€æ”¾å¼æŒ‘æˆ˜: è¯·å®ç°æ‚¨è‡ªå·±çš„ç½‘ç»œï¼Œä»¥åœ¨ CIFAR-10 ä¸Šè·å¾—å°½å¯èƒ½é«˜çš„å‡†ç¡®æ€§ã€‚æ‚¨å¯ä»¥å°è¯•ä»»ä½•å±‚ã€ä¼˜åŒ–å™¨ã€è¶…å‚æ•°æˆ–å…¶ä»–é«˜çº§åŠŸèƒ½ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒè¡¨:\n",
    "\n",
    "| API           | çµæ´»æ€§ | ä¾¿æ·åº¦ |\n",
    "|---------------|-------------|-------------|\n",
    "| Barebone      | é«˜        | ä½         |\n",
    "| `nn.Module`     | é«˜        | ä¸­      |\n",
    "| `nn.Sequential` | ä½         | é«˜        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. å‡†å¤‡å·¥ä½œ\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬åŠ è½½ CIFAR-10 æ•°æ®é›†ã€‚ç¬¬ä¸€æ¬¡æ‰§è¡Œæ­¤æ“ä½œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œä½†æ­¤åæ–‡ä»¶åº”ä¿ç•™åœ¨ç¼“å­˜ä¸­ã€‚\n",
    "\n",
    "åœ¨ä½œä¸šçš„å‰é¢éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å¿…é¡»ç¼–å†™è‡ªå·±çš„ä»£ç æ¥ä¸‹è½½ CIFAR-10 æ•°æ®é›†ã€å¯¹å…¶è¿›è¡Œé¢„å¤„ç†å¹¶ä»¥å°æ‰¹é‡æ–¹å¼è¿­ä»£å®ƒï¼› PyTorch æä¾›äº†æ–¹ä¾¿çš„å·¥å…·æ¥ä¸ºæˆ‘ä»¬è‡ªåŠ¨åŒ–è¿™ä¸ªè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./ds204-lab/datasets\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [12:36<00:00, 225376.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./ds204-lab/datasets\\cifar-10-python.tar.gz to ./ds204-lab/datasets\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "# torchvision.transforms åŒ…æä¾›äº†ç”¨äºé¢„å¤„ç†æ•°æ®çš„å·¥å…·ä»¥åŠç”¨äºæ‰§è¡Œæ•°æ®å¢å¼ºï¼›åœ¨è¿™é‡Œæˆ‘ä»¬è®¾ç½®äº†ä¸€ä¸ªè½¬æ¢\n",
    "# é€šè¿‡å‡å»å¹³å‡ RGB å€¼å¹¶é™¤ä»¥æ¯ä¸ªRGBå€¼çš„æ ‡å‡†å·®ï¼›æˆ‘ä»¬å·²ç»å¯¹å¹³å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œäº†ç¡¬ç¼–ç ã€‚\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# æˆ‘ä»¬ä¸ºæ¯ä¸ªåˆ†å‰²ï¼ˆtrain / val / testï¼‰è®¾ç½®ä¸€ä¸ªDatasetå¯¹è±¡ï¼›æ•°æ®é›†ä¸€æ¬¡åŠ è½½ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹\n",
    "# å› æ­¤ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªæ•°æ®é›†åŒ…è£…åœ¨ DataLoader ä¸­ï¼Œè¯¥æ•°æ®åŠ è½½å™¨è¿­ä»£æ•°æ®é›†å¹¶å½¢æˆå°æ‰¹é‡ã€‚\n",
    "# æˆ‘ä»¬é€šè¿‡å°† Sampler å¯¹è±¡ä¼ é€’ç»™ CIFAR-10 è®­ç»ƒé›†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚\n",
    "# DataLoader å‘Šè¯‰å®ƒåº”è¯¥å¦‚ä½•ä»åº•å±‚æ•°æ®é›†ä¸­é‡‡æ ·ã€‚\n",
    "cifar10_train = dset.CIFAR10('./ds204-lab/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./ds204-lab/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./ds204-lab/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‚¨å¯ä»¥é€‰æ‹© **é€šè¿‡å°†ä¸‹é¢USE_GPUçš„æ ‡å¿—è®¾ç½®ä¸º True æ¥ä½¿ç”¨ GPU**. æ­¤ä»»åŠ¡æ— éœ€ä½¿ç”¨ GPUã€‚è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨çš„è®¡ç®—æœºæœªå¯ç”¨CUDA , `torch.cuda.is_available()` å°†è¿”å› Falseï¼Œå¹¶ä¸”æ­¤ç¬”è®°æœ¬å°†å›é€€åˆ° CPU æ¨¡å¼ã€‚\n",
    "\n",
    "å…¨å±€å˜é‡ `dtype` å’Œ `device`å°†æ§åˆ¶æ•´ä¸ªåˆ†é…è¿‡ç¨‹ä¸­çš„æ•°æ®ç±»å‹ã€‚ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Barebones PyTorch\n",
    "\n",
    "PyTorch é™„å¸¦äº†é«˜çº§ APIï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ–¹ä¾¿åœ°å®šä¹‰æ¨¡å‹æ¶æ„ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬æ•™ç¨‹çš„ç¬¬äºŒéƒ¨åˆ†ä¸­ä»‹ç»è¿™ä¸€ç‚¹ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»å‡†ç³»ç»Ÿ PyTorch å…ƒç´ å¼€å§‹ï¼Œä»¥æ›´å¥½åœ°äº†è§£ Autograd å¼•æ“ã€‚å®Œæˆæœ¬æ¬¡ç»ƒä¹ åï¼Œæ‚¨å°†æ›´åŠ äº†è§£é«˜çº§æ¨¡å‹ APIã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ä»ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ ReLU ç½‘ç»œå¼€å§‹ï¼Œè¯¥ç½‘ç»œå…·æœ‰ä¸¤ä¸ªéšè—å±‚å¹¶ä¸”å¯¹ CIFAR åˆ†ç±»æ²¡æœ‰åå·®ã€‚\n",
    "æ­¤å®ç°ä½¿ç”¨ PyTorch å¼ é‡ä¸Šçš„æ“ä½œæ¥è®¡ç®—å‰å‘ä¼ é€’ï¼Œå¹¶ä½¿ç”¨ PyTorch Autograd æ¥è®¡ç®—æ¢¯åº¦ã€‚ç†è§£æ¯ä¸€è¡Œå¾ˆé‡è¦ï¼Œå› ä¸ºåœ¨ç¤ºä¾‹ä¹‹åæ‚¨å°†ç¼–å†™ä¸€ä¸ªæ›´éš¾çš„ç‰ˆæœ¬ã€‚\n",
    "\n",
    "å½“æˆ‘ä»¬åˆ›å»º PyTorch å¼ é‡æ—¶ `requires_grad=True`,é‚£ä¹ˆæ¶‰åŠè¯¥å¼ é‡çš„è¿ç®—å°†ä¸ä»…ä»…æ˜¯è®¡ç®—å€¼ï¼›ä»–ä»¬è¿˜å°†åœ¨åå°å»ºç«‹ä¸€ä¸ªè®¡ç®—å›¾ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè½»æ¾åœ°é€šè¿‡è¯¥å›¾è¿›è¡Œåå‘ä¼ æ’­ï¼Œä»¥è®¡ç®—ä¸€äº›å¼ é‡ç›¸å¯¹äºä¸‹æ¸¸æŸå¤±çš„æ¢¯åº¦ã€‚ å…·ä½“æ¥è¯´ï¼Œå¦‚æœ x æ˜¯ä¸€ä¸ªå¼ é‡ `x.requires_grad == True` é‚£ä¹ˆåœ¨åå‘ä¼ æ’­ä¹‹åï¼Œ`x.grad` å°†æ˜¯å¦ä¸€ä¸ªå¼ é‡ï¼Œå®ƒä¿å­˜ç€ x ç›¸å¯¹äºæœ€åçš„æ ‡é‡æŸå¤±çš„æ¢¯åº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch å¼ é‡(Tensor): å±•å¹³å‡½æ•°\n",
    "PyTorch å¼ é‡åœ¨æ¦‚å¿µä¸Šç±»ä¼¼äº numpy æ•°ç»„ï¼šå®ƒæ˜¯ä¸€ä¸ª n ç»´æ•°å­—ç½‘æ ¼ï¼Œå¹¶ä¸”ä¸ numpy ä¸€æ ·ï¼ŒPyTorch æä¾›äº†è®¸å¤šå‡½æ•°æ¥æœ‰æ•ˆåœ°å¯¹å¼ é‡è¿›è¡Œæ“ä½œã€‚ä½œä¸ºä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ª `(å±•å¹³)flatten` å‡½æ•°ï¼Œå®ƒå¯ä»¥é‡å¡‘å›¾åƒæ•°æ®ä»¥ç”¨äºå…¨è¿æ¥çš„ç¥ç»ç½‘ç»œã€‚\n",
    "\n",
    "å›æƒ³ä¸€ä¸‹ï¼Œå›¾åƒæ•°æ®é€šå¸¸å­˜å‚¨åœ¨å½¢çŠ¶ä¸º N x C x H x W çš„å¼ é‡ä¸­ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "* N æ˜¯æ•°æ®ç‚¹çš„æ•°é‡\n",
    "* Cæ˜¯é€šé“æ•°\n",
    "* H æ˜¯ä¸­é—´ç‰¹å¾å›¾çš„é«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰\n",
    "* W æ˜¯ä¸­é—´ç‰¹å¾å›¾çš„å®½åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰\n",
    "\n",
    "å½“æˆ‘ä»¬è¿›è¡Œ 2D å·ç§¯ä¹‹ç±»çš„æ“ä½œæ—¶ï¼Œè¿™æ˜¯è¡¨ç¤ºæ•°æ®çš„æ­£ç¡®æ–¹æ³•ï¼Œè¿™éœ€è¦å¯¹ä¸­é—´ç‰¹å¾å½¼æ­¤ç›¸å¯¹çš„ä½ç½®è¿›è¡Œç©ºé—´ç†è§£ã€‚ ç„¶è€Œï¼Œå½“æˆ‘ä»¬ä½¿ç”¨å…¨è¿æ¥çš„ä»¿å°„å±‚æ¥å¤„ç†å›¾åƒæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æ¯ä¸ªæ•°æ®ç‚¹éƒ½ç”±å•ä¸ªå‘é‡è¡¨ç¤º - éš”ç¦»æ•°æ®çš„ä¸åŒé€šé“ã€è¡Œå’Œåˆ—ä¸å†æœ‰ç”¨ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œå±•å¹³â€æ“ä½œå°†æ¯ä¸ªè¡¨ç¤ºçš„â€œC x H x Wâ€å€¼æŠ˜å ä¸ºå•ä¸ªé•¿å‘é‡ã€‚ ä¸‹é¢çš„ flatten å‡½æ•°é¦–å…ˆä»ç»™å®šçš„ä¸€æ‰¹æ•°æ®ä¸­è¯»å– Nã€Cã€H å’Œ W å€¼ï¼Œç„¶åè¿”å›è¯¥æ•°æ®çš„â€œè§†å›¾â€ã€‚ â€œViewâ€ç±»ä¼¼äº numpy çš„â€œreshapeâ€æ–¹æ³•ï¼šå®ƒå°† x çš„ç»´åº¦é‡å¡‘ä¸º N x ??ï¼Œå…¶ä¸­ ??å…è®¸æ˜¯ä»»ä½•ä¸œè¥¿ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œå®ƒå°†æ˜¯ C x H x Wï¼Œä½†æˆ‘ä»¬ä¸éœ€è¦æ˜ç¡®æŒ‡å®šï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # è¯»å– N, C, H, W\n",
    "    return x.view(N, -1)  # \"å±•å¹³\"  C * H * W çš„å€¼ï¼Œè½¬åŒ–ä¸ºæ¯ä¸ªå›¾åƒçš„å•ä¸ªå‘é‡\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: åŒå±‚ç½‘ç»œ\n",
    "\n",
    "è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå‡½æ•° `two_layer_fc`ï¼Œå®ƒå¯¹ä¸€æ‰¹å›¾åƒæ•°æ®æ‰§è¡Œä¸¤å±‚å…¨è¿æ¥ ReLU ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚å®šä¹‰å‰å‘ä¼ é€’åï¼Œæˆ‘ä»¬æ£€æŸ¥å®ƒæ˜¯å¦ä¸ä¼šå´©æºƒï¼Œå¹¶ä¸”é€šè¿‡åœ¨ç½‘ç»œä¸­è¿è¡Œé›¶æ¥ç”Ÿæˆæ­£ç¡®å½¢çŠ¶çš„è¾“å‡ºã€‚\n",
    "\n",
    "æ‚¨ä¸å¿…åœ¨è¿™é‡Œç¼–å†™ä»»ä½•ä»£ç ï¼Œä½†é˜…è¯»å¹¶ç†è§£å®ç°éå¸¸é‡è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # æœ‰ç”¨çš„æ— çŠ¶æ€å‡½æ•°\n",
    "\n",
    "def two_layer_fc(x, params):\n",
    "    \"\"\"\n",
    "    å…¨è¿æ¥çš„ç¥ç»ç½‘ç»œï¼›\n",
    "    å…¶æ¡†æ¶æ˜¯:\n",
    "    NN ä¸º  å…¨è¿æ¥-> ReLU -> å…¨è¿æ¥å±‚ã€‚\n",
    "    æ³¨æ„è¿™ä¸ªå‡½æ•°åªå®šä¹‰äº†å‰å‘ä¼ æ’­ï¼›\n",
    "    PyTorch å°†ä¸ºæˆ‘ä»¬å¤„ç†å‘åä¼ é€’ã€‚\n",
    "    \n",
    "    ç½‘ç»œçš„è¾“å…¥å°†æ˜¯ä¸€å°æ‰¹æ•°æ®ï¼Œ å…¶å½¢çŠ¶\n",
    "    (N, d1, ..., dM) å…¶ä¸­ d1 * ... * dM = Dã€‚ Téšè—å±‚å°†æœ‰ H ä¸ªå•å…ƒï¼Œ\n",
    "    è¾“å‡ºå±‚å°†äº§ç”Ÿ C ç±»çš„åˆ†æ•°ã€‚\n",
    "    \n",
    "    è¾“å…¥:\n",
    "    - x: å½¢çŠ¶ä¸º (N, d1, ..., dM) çš„ PyTorch å¼ é‡ï¼Œç»™å‡ºçš„å°æ‰¹é‡è¾“å…¥æ•°æ®ã€‚\n",
    "    - params:PyTorch å¼ é‡åˆ—è¡¨ [w1, w2] ä¸ºç½‘ç»œæä¾›æƒé‡ï¼›w1 å…·æœ‰å½¢çŠ¶ (D, H)ï¼Œw2 å…·æœ‰å½¢çŠ¶ (H, C)ã€‚\n",
    "    \n",
    "    è¿”å›:\n",
    "    - scores: å½¢çŠ¶ä¸º (N, C) çš„ PyTorch å¼ é‡ï¼Œç»™å‡ºè¾“å…¥æ•°æ®xçš„åˆ†ç±»åˆ†æ•°ã€‚\n",
    "    \"\"\"\n",
    "    # é¦–å…ˆæˆ‘ä»¬å±•å¹³å›¾åƒ\n",
    "    x = flatten(x)  # shape: [batch_size, C x H x W]\n",
    "    \n",
    "    w1, w2 = params\n",
    "    \n",
    "    # å‰å‘ä¼ é€’: ä½¿ç”¨å¼ é‡è¿ç®—è®¡ç®—é¢„æµ‹ y. w1å’Œw2çš„ requires_grad=Trueï¼Œ\n",
    "    # æ¶‰åŠè¿™äº›Tensorsçš„æ“ä½œä¼šå¯¼è‡´PyTorch æ„å»ºè®¡ç®—å›¾ï¼Œå…è®¸è‡ªåŠ¨è®¡ç®—æ¢¯åº¦\n",
    "    # å› æ­¤æˆ‘ä»¬ä¸å†æ‰‹åŠ¨å®ç°å‘åä¼ é€’ ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä¿ç•™å¯¹ä¸­é—´å€¼çš„å¼•ç”¨ã€‚\n",
    "    # ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`.clamp(min=0)`, ç›¸å½“äºF.relu()\n",
    "    x = F.relu(x.mm(w1))\n",
    "    x = x.mm(w2)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def two_layer_fc_test():\n",
    "    hidden_layer_size = 42\n",
    "    x = torch.zeros((64, 50), dtype=dtype)  # å°æ‰¹é‡å¤§å° 64,ç‰¹å¾ç»´åº¦ 50\n",
    "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n",
    "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n",
    "    scores = two_layer_fc(x, [w1, w2])\n",
    "    print(scores.size())  # ä½ åº”è¯¥çœ‹åˆ°è¾“å‡ºä¸º [64, 10]\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: ä¸‰å±‚å·ç§¯ç½‘ç»œ\n",
    "\n",
    "åœ¨è¿™é‡Œï¼Œæ‚¨å°†å®Œæˆå‡½æ•° `three_layer_convnet`çš„å®ç°, è¯¥å‡½æ•°å°†æ‰§è¡Œä¸‰å±‚å·ç§¯ç½‘ç»œçš„å‘å‰ä¼ é€’ã€‚ åƒä¸Šé¢ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç½‘ç»œä¼ é€’é›¶æ¥ç«‹å³æµ‹è¯•æˆ‘ä»¬çš„å®ç°ã€‚ç½‘ç»œåº”å…·æœ‰ä»¥ä¸‹æ¶æ„ï¼š\n",
    "1. å¸¦æœ‰`channel_1`æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦æœ‰åå·®ï¼‰ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨çš„å½¢çŠ¶ä¸º`KW1 x KH1`ï¼Œä»¥åŠä¸¤ä¸ªé›¶å¡«å……\n",
    "2. éçº¿æ€§ReLU\n",
    "3. å¸¦æœ‰`channel_2`æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦æœ‰åå·®ï¼‰ï¼Œæ¯ä¸ªæ»¤æ³¢å™¨çš„å½¢çŠ¶ä¸º`KW2 x KH2`ï¼Œä»¥åŠä¸¤ä¸ªé›¶å¡«å……\n",
    "4. éçº¿æ€§ReLU\n",
    "5. å¸¦åå·®çš„å…¨è¿æ¥å±‚ï¼Œä¸º C ç±»ç”Ÿæˆåˆ†æ•°ã€‚\n",
    "\n",
    "**æç¤º**: å¯¹äºå·ç§¯: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; æ³¨æ„å·ç§¯æ»¤æ³¢å™¨çš„å½¢çŠ¶ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„æ¶æ„æ‰§è¡Œä¸‰å±‚å·ç§¯ç½‘ç»œçš„å‰å‘ä¼ é€’ã€‚\n",
    "\n",
    "    è¾“å…¥:\n",
    "    - x: æä¾›å°æ‰¹é‡å›¾åƒå½¢çŠ¶ (N, 3, H, W) çš„ PyTorch å¼ é‡ï¼Œ\n",
    "    - params: ç»™å‡ºç½‘ç»œæƒé‡å’Œåå·®çš„ PyTorch å¼ é‡åˆ—è¡¨ï¼›\n",
    "    åº”åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š\n",
    "      - conv_w1ï¼šå½¢çŠ¶ (channel_1, 3, KH1, KW1) çš„ PyTorch å¼ é‡ï¼Œç»™å‡ºç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„æƒé‡\n",
    "      - conv_b1: å½¢çŠ¶ (channel_1,) çš„ PyTorch å¼ é‡ç»™å‡ºç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„åå·®\n",
    "      - conv_w2: å½¢çŠ¶ (channel_2, channel_1, KH2, KW2) çš„ PyTorch å¼ é‡ï¼Œç»™å‡ºç¬¬äºŒä¸ªå·ç§¯å±‚çš„æƒé‡\n",
    "      - conv_b2: å½¢çŠ¶ (channel_2,) çš„ PyTorch å¼ é‡ç»™å‡ºç¬¬äºŒä¸ªå·ç§¯å±‚çš„åå·®\n",
    "      - fc_w: PyTorch Tensor ä¸ºå…¨è¿æ¥å±‚èµ‹äºˆæƒé‡ã€‚ä½ èƒ½çŒœå‡ºå®ƒåº”è¯¥æ˜¯ä»€ä¹ˆå½¢çŠ¶å—ï¼Ÿ\n",
    "      - fc_b: PyTorch Tensor ä¸ºå…¨è¿æ¥å±‚æä¾›åå·®ã€‚ä½ èƒ½çŒœå‡ºå®ƒåº”è¯¥æ˜¯ä»€ä¹ˆå½¢çŠ¶å—ï¼Ÿ\n",
    "    \n",
    "    è¿”å›:\n",
    "    - scores: å½¢çŠ¶ (N, C) çš„ PyTorch å¼ é‡ç»™å‡º x çš„åˆ†ç±»åˆ†æ•°\n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    ################################################################################\n",
    "    # TODO: å®ç°ä¸‰å±‚ ConvNet çš„å‰å‘ä¼ é€’ã€‚                                           #\n",
    "    ################################################################################\n",
    "    #       *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****          #\n",
    "    ################################################################################\n",
    "    \n",
    "  \n",
    "    conv1 = F.conv2d(x, weight=conv_w1, bias=conv_b1, padding=2)\n",
    "    relu1 = F.relu(conv1)\n",
    "    conv2 = F.conv2d(relu1, weight=conv_w2, bias=conv_b2, padding=1)\n",
    "    relu2 = F.relu(conv2)\n",
    "    relu2_flat = flatten(relu2)\n",
    "    scores = relu2_flat.mm(fc_w) + fc_b\n",
    "    \n",
    "    ################################################################################\n",
    "    #                                END OF YOUR CODE                              #\n",
    "    ################################################################################\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰ä¸Šè¿° ConvNet çš„å‰å‘ä¼ é€’åï¼Œè¿è¡Œä»¥ä¸‹å•å…ƒæ¥æµ‹è¯•æ‚¨çš„å®ç°ã€‚\n",
    "\n",
    "å½“æ‚¨è¿è¡Œæ­¤å‡½æ•°æ—¶ï¼Œscoresçš„å½¢çŠ¶åº”ä¸º (64, 10)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # å°æ‰¹é‡å¤§å° 64, å›¾ç‰‡å¤§å° [3, 32, 32]\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b1 = torch.zeros((6,))  # out_channel\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b2 = torch.zeros((9,))  # out_channel\n",
    "\n",
    "    # æ‚¨å¿…é¡»åœ¨ä¸¤ä¸ªè½¬æ¢å±‚ä¹‹åã€å…¨è¿æ¥å±‚ä¹‹å‰è®¡ç®—å¼ é‡çš„å½¢çŠ¶\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
    "    fc_b = torch.zeros(10)\n",
    "\n",
    "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())  # ä½ åº”è¯¥çœ‹åˆ°[64, 10]\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: åˆå§‹åŒ–\n",
    "è®©æˆ‘ä»¬ç¼–å†™å‡ ä¸ªå®ç”¨æ–¹æ³•æ¥åˆå§‹åŒ–æ¨¡å‹çš„æƒé‡çŸ©é˜µã€‚\n",
    "\n",
    "- `random_weight(shape)` ä½¿ç”¨ Kaiming å½’ä¸€åŒ–æ–¹æ³•åˆå§‹åŒ–æƒé‡å¼ é‡ã€‚\n",
    "- `zero_weight(shape)` ç”¨å…¨é›¶åˆå§‹åŒ–æƒé‡å¼ é‡ã€‚å¯¹äºå®ä¾‹åŒ–åç½®å‚æ•°å¾ˆæœ‰ç”¨ã€‚\n",
    "\n",
    "`random_weight` å‡½æ•°ä½¿ç”¨Kaimingæ™®é€šåˆå§‹åŒ–æ–¹æ³•ï¼Œæè¿°å¦‚ä¸‹\n",
    "\n",
    "He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4758, -0.7288, -0.7309, -0.6499,  0.1560],\n",
       "        [ 0.1188,  0.2502, -0.4702,  0.5564, -0.2477],\n",
       "        [-1.1646, -1.2569,  0.6985, -0.6833, -1.2493]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "   ä¸ºæƒé‡åˆ›å»ºéšæœºå¼ é‡ï¼›è®¾ç½® requires_grad=True æ„å‘³ç€æˆ‘ä»¬\n",
    "    æƒ³è¦åœ¨å‘åä¼ é€’è¿‡ç¨‹ä¸­è®¡ç®—è¿™äº›å¼ é‡çš„æ¢¯åº¦ã€‚\n",
    "    æˆ‘ä»¬ä½¿ç”¨ Kaiming å½’ä¸€åŒ–: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒç”Ÿæˆå™¨ã€‚ \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# åˆ›å»ºæƒé‡çš„å½¢çŠ¶ [3 x 5]\n",
    "# å¦‚æœæ‚¨ä½¿ç”¨ GPUï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°`torch.cuda.FloatTensor`ç±»å‹ã€‚\n",
    "# å¦åˆ™å®ƒåº”è¯¥æ˜¯  `torch.FloatTensor`\n",
    "random_weight((3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: æ£€æŸ¥å‡†ç¡®æ€§\n",
    "è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹å‡½æ•°æ¥æ£€æŸ¥æ¨¡å‹åœ¨è®­ç»ƒæˆ–éªŒè¯é›†ä¸Šçš„å‡†ç¡®æ€§ã€‚\n",
    "\n",
    "æ£€æŸ¥å‡†ç¡®æ€§æ—¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦è®¡ç®—ä»»ä½•æ¢¯åº¦ï¼›å› æ­¤ï¼Œå½“æˆ‘ä»¬è®¡ç®—åˆ†æ•°æ—¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦ PyTorch ä¸ºæˆ‘ä»¬æ„å»ºè®¡ç®—å›¾ã€‚ä¸ºäº†é˜²æ­¢æ„å»ºå›¾è¡¨ï¼Œæˆ‘ä»¬å°†è®¡ç®—èŒƒå›´é™åˆ¶åœ¨`torch.no_grad()`ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part2(loader, model_fn, params):\n",
    "    \"\"\"\n",
    "   æ£€æŸ¥åˆ†ç±»æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚\n",
    "    \n",
    "    è¾“å…¥:\n",
    "    - loader:ç”¨äºæˆ‘ä»¬è¦æ£€æŸ¥çš„æ•°æ®åˆ†å‰²çš„ DataLoader\n",
    "    - model_fn:æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ é€’çš„å‡½æ•°ï¼Œç­¾åä¸º Score = model_fn(x, params)\n",
    "    - params: ç»™å‡ºæ¨¡å‹å‚æ•°çš„ PyTorch å¼ é‡åˆ—è¡¨\n",
    "    \n",
    "    è¿”å›:Nothing, ä½†æ‰“å°æ¨¡å‹çš„å‡†ç¡®æ€§\n",
    "    \"\"\"\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # æ›´æ¢è®¾å¤‡ï¼Œå¦‚GPU\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model_fn(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: è®­ç»ƒå¾ªç¯\n",
    "æˆ‘ä»¬ç°åœ¨å¯ä»¥å»ºç«‹ä¸€ä¸ªåŸºæœ¬çš„è®­ç»ƒå¾ªç¯æ¥è®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ— åŠ¨é‡çš„éšæœºæ¢¯åº¦ä¸‹é™æ¥è®­ç»ƒæ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`torch.function.cross_entropy`æ¥è®¡ç®—æŸå¤±ï¼› ä½ å¯ä»¥ [åœ¨è¿™é‡Œé˜…è¯»ç›¸å…³å†…å®¹](http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
    "\n",
    "è®­ç»ƒå¾ªç¯å°†ç¥ç»ç½‘ç»œå‡½æ•°ã€åˆå§‹åŒ–å‚æ•°åˆ—è¡¨ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸º`[w1, w2]`ï¼‰å’Œå­¦ä¹ ç‡ä½œä¸ºè¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part2(model_fn, params, learning_rate):\n",
    "    \"\"\"\n",
    "    åœ¨ CIFAR-10 ä¸Šè®­ç»ƒæ¨¡å‹ã€‚\n",
    "    \n",
    "    è¾“å…¥:\n",
    "    - model_fn:æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­çš„ Python å‡½æ•°ã€‚å®ƒåº”è¯¥å…·æœ‰ç­¾å Score = model_fn(x, params) \n",
    "      å…¶ä¸­ x æ˜¯å›¾åƒæ•°æ®çš„ PyTorch å¼ é‡ï¼Œparams æ˜¯ PyTorch å¼ é‡çš„åˆ—è¡¨æ¨¡å‹æƒé‡ï¼Œ\n",
    "      åˆ†æ•°æ˜¯å½¢çŠ¶ (N, C) çš„ PyTorch å¼ é‡ x ä¸­å…ƒç´ çš„åˆ†æ•°ã€‚\n",
    "    - params:èµ‹äºˆæ¨¡å‹æƒé‡çš„ PyTorch å¼ é‡åˆ—è¡¨\n",
    "    - learning_rate: Python æ ‡é‡ç»™å‡ºç”¨äº SGD çš„å­¦ä¹ ç‡\n",
    "    \n",
    "    è¿”å›: Nothing\n",
    "    \"\"\"\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        # å°†æ•°æ®ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡ï¼ˆGPU æˆ– CPUï¼‰\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "        # å‰å‘ä¼ é€’ï¼šè®¡ç®—åˆ†æ•°å’ŒæŸå¤±\n",
    "        scores = model_fn(x, params)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        # å‘åä¼ é€’ï¼šPyTorch æ‰¾å‡ºè®¡ç®—å›¾ä¸­å“ªäº›å¼ é‡å…·æœ‰ require_grad=True \n",
    "        # å¹¶ä½¿ç”¨åå‘ä¼ æ’­æ¥è®¡ç®—ç›¸å¯¹äºè¿™äº›å¼ é‡çš„æŸå¤±æ¢¯åº¦ï¼Œ\n",
    "        # å¹¶å°†æ¢¯åº¦å­˜å‚¨åœ¨æ¯ä¸ª Tensor çš„ .grad å±æ€§ä¸­ã€‚\n",
    "        loss.backward()\n",
    "\n",
    "        # æ›´æ–°å‚æ•°ã€‚ \n",
    "        #æˆ‘ä»¬ä¸æƒ³é€šè¿‡å‚æ•°æ›´æ–°è¿›è¡Œåå‘ä¼ æ’­ï¼Œ\n",
    "        #å› æ­¤æˆ‘ä»¬å°†æ›´æ–°èŒƒå›´é™åˆ¶åœ¨ torch.no_grad() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸‹ï¼Œä»¥é˜²æ­¢æ„å»ºè®¡ç®—å›¾ã€‚\n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "\n",
    "                # è¿è¡Œåå‘ä¼ æ’­åæ‰‹åŠ¨å°†æ¢¯åº¦å½’é›¶\n",
    "                w.grad.zero_()\n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            check_accuracy_part2(loader_val, model_fn, params)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: è®­ç»ƒä¸¤å±‚ç½‘ç»œ\n",
    "ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½è¿è¡Œè®­ç»ƒå¾ªç¯äº†ã€‚æˆ‘ä»¬éœ€è¦ä¸ºå…¨è¿æ¥æƒé‡`w1`å’Œ`w2`æ˜¾å¼åˆ†é…å¼ é‡ã€‚ \n",
    "\n",
    "CIFAR çš„æ¯ä¸ªå°æ‰¹é‡æœ‰ 64 ä¸ªç¤ºä¾‹ï¼Œå› æ­¤å¼ é‡å½¢çŠ¶ä¸º `[64, 3, 32, 32]`ã€‚\n",
    "\n",
    "å±•å¹³å, `x` çš„å½¢çŠ¶åº”ä¸º`[64, 3 * 32 * 32]`. ä»–å°†æ˜¯`w1`ç¬¬ä¸€ä¸ªç»´åº¦çš„å¤§å°ã€‚ \n",
    "`w1`çš„ç¬¬äºŒä¸ªç»´åº¦æ˜¯éšè—å±‚å¤§å°ï¼Œè¿™ä¹Ÿæ˜¯`w2`çš„ç¬¬ä¸€ä¸ªç»´åº¦ã€‚ \n",
    "\n",
    "æœ€åï¼Œç½‘ç»œçš„è¾“å‡ºæ˜¯ä¸€ä¸ª 10 ç»´å‘é‡ï¼Œè¡¨ç¤º 10 ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "\n",
    "æ‚¨ä¸éœ€è¦è°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†åœ¨è®­ç»ƒä¸€ä¸ª epoch åï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°å‡†ç¡®ç‡é«˜äº 40%ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.1638\n",
      "Checking accuracy on the val set\n",
      "Got 141 / 1000 correct (14.10%)\n",
      "\n",
      "Iteration 100, loss = 2.0802\n",
      "Checking accuracy on the val set\n",
      "Got 345 / 1000 correct (34.50%)\n",
      "\n",
      "Iteration 200, loss = 2.5873\n",
      "Checking accuracy on the val set\n",
      "Got 364 / 1000 correct (36.40%)\n",
      "\n",
      "Iteration 300, loss = 2.0787\n",
      "Checking accuracy on the val set\n",
      "Got 382 / 1000 correct (38.20%)\n",
      "\n",
      "Iteration 400, loss = 2.0624\n",
      "Checking accuracy on the val set\n",
      "Got 419 / 1000 correct (41.90%)\n",
      "\n",
      "Iteration 500, loss = 1.7178\n",
      "Checking accuracy on the val set\n",
      "Got 417 / 1000 correct (41.70%)\n",
      "\n",
      "Iteration 600, loss = 2.2978\n",
      "Checking accuracy on the val set\n",
      "Got 427 / 1000 correct (42.70%)\n",
      "\n",
      "Iteration 700, loss = 1.3888\n",
      "Checking accuracy on the val set\n",
      "Got 405 / 1000 correct (40.50%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size, 10))\n",
    "\n",
    "train_part2(two_layer_fc, [w1, w2], learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: è®­ç»ƒå·ç§¯ç½‘ç»œ\n",
    "\n",
    "åœ¨ä¸‹é¢ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„å‡½æ•°åœ¨ CIFAR ä¸Šè®­ç»ƒä¸‰å±‚å·ç§¯ç½‘ç»œã€‚ç½‘ç»œåº”å…·æœ‰ä»¥ä¸‹æ¶æ„ï¼š\n",
    "\n",
    "1. å…·æœ‰ 32 ä¸ª 5x5 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦åç½®ï¼‰ï¼Œé›¶å¡«å……ä¸º 2\n",
    "2. ReLU\n",
    "3. å…·æœ‰ 16 ä¸ª 3x3 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦åç½®ï¼‰ï¼Œé›¶å¡«å……ä¸º 1\n",
    "4. ReLU\n",
    "5. å…¨è¿æ¥å±‚ï¼ˆå¸¦æœ‰åå·®ï¼‰è®¡ç®— 10 ä¸ªç±»åˆ«çš„åˆ†æ•°\n",
    "\n",
    "æ‚¨åº”è¯¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„`random_weight`å‡½æ•°åˆå§‹åŒ–æƒé‡çŸ©é˜µï¼Œå¹¶ä¸”åº”è¯¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„`zero_weight`å‡½æ•°åˆå§‹åŒ–åå·®å‘é‡ã€‚\n",
    "\n",
    "æ‚¨ä¸éœ€è¦è°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œæ‚¨åº”è¯¥åœ¨ä¸€ä¸ª epoch åè¾¾åˆ° 42% ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.9098\n",
      "Checking accuracy on the val set\n",
      "Got 115 / 1000 correct (11.50%)\n",
      "\n",
      "Iteration 100, loss = 1.7671\n",
      "Checking accuracy on the val set\n",
      "Got 360 / 1000 correct (36.00%)\n",
      "\n",
      "Iteration 200, loss = 1.4617\n",
      "Checking accuracy on the val set\n",
      "Got 399 / 1000 correct (39.90%)\n",
      "\n",
      "Iteration 300, loss = 1.9257\n",
      "Checking accuracy on the val set\n",
      "Got 447 / 1000 correct (44.70%)\n",
      "\n",
      "Iteration 400, loss = 1.7655\n",
      "Checking accuracy on the val set\n",
      "Got 451 / 1000 correct (45.10%)\n",
      "\n",
      "Iteration 500, loss = 1.4304\n",
      "Checking accuracy on the val set\n",
      "Got 486 / 1000 correct (48.60%)\n",
      "\n",
      "Iteration 600, loss = 1.4907\n",
      "Checking accuracy on the val set\n",
      "Got 478 / 1000 correct (47.80%)\n",
      "\n",
      "Iteration 700, loss = 1.5136\n",
      "Checking accuracy on the val set\n",
      "Got 486 / 1000 correct (48.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "conv_w1 = None\n",
    "conv_b1 = None\n",
    "conv_w2 = None\n",
    "conv_b2 = None\n",
    "fc_w = None\n",
    "fc_b = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: åˆå§‹åŒ–ä¸‰å±‚ConvNetçš„å‚æ•°ã€‚                                              #\n",
    "################################################################################\n",
    "#       *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****          #\n",
    "################################################################################\n",
    "\n",
    "conv_w1 = random_weight((channel_1, 3, 5, 5))\n",
    "conv_b1 = zero_weight((channel_1,))\n",
    "conv_w2 = random_weight((channel_2, 32, 3, 3))\n",
    "conv_b2 = zero_weight((channel_2,))\n",
    "fc_w = random_weight((channel_2*32*32, 10))\n",
    "fc_b = zero_weight((10,))\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. PyTorch Module API\n",
    "\n",
    "Barebone PyTorch è¦æ±‚æˆ‘ä»¬æ‰‹åŠ¨è·Ÿè¸ªæ‰€æœ‰å‚æ•°å¼ é‡ã€‚è¿™å¯¹äºå…·æœ‰å‡ ä¸ªå¼ é‡çš„å°å‹ç½‘ç»œæ¥è¯´å¾ˆå¥½ï¼Œä½†åœ¨è¾ƒå¤§çš„ç½‘ç»œä¸­è·Ÿè¸ªæ•°åæˆ–æ•°ç™¾ä¸ªå¼ é‡å°†éå¸¸ä¸æ–¹ä¾¿ä¸”å®¹æ˜“å‡ºé”™ã€‚\n",
    "\n",
    "PyTorch æä¾›`nn.Module` API ä¾›æ‚¨å®šä¹‰ä»»æ„ç½‘ç»œæ¶æ„ï¼ŒåŒæ—¶ä¸ºæ‚¨è·Ÿè¸ªæ¯ä¸ªå¯å­¦ä¹ çš„å‚æ•°ã€‚ åœ¨Part IIä¸­, æˆ‘ä»¬è‡ªå·±å®æ–½äº†SGD(æ¢¯åº¦ä¸‹é™). PyTorch  è¿˜æä¾›äº†  `torch.optim` åŒ…ï¼Œå®ƒå®ç°äº†æ‰€æœ‰å¸¸è§çš„ä¼˜åŒ–å™¨ï¼Œ ä¾‹å¦‚ RMSProp, Adagrad å’Œ Adam. å®ƒç”šè‡³æ”¯æŒè¿‘ä¼¼äºŒé˜¶æ–¹æ³•ï¼Œå¦‚ L-BFGSï¼æ‚¨å¯ä»¥å‚è€ƒ[æ–‡æ¡£](http://pytorch.org/docs/master/optim.html)äº†è§£æ¯ä¸ªä¼˜åŒ–å™¨çš„å…·ä½“è§„æ ¼ã€‚\n",
    "\n",
    "è¦ä½¿ç”¨æ¨¡å— APIï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š\n",
    "\n",
    "1. å­ç±»`nn.Module`ã€‚ä¸ºæ‚¨çš„ç½‘ç»œç±»æŒ‡å®šä¸€ä¸ªç›´è§‚çš„åç§°ï¼Œä¾‹å¦‚`TwoLayerFC`ã€‚\n",
    "\n",
    "2. åœ¨æ„é€ å‡½æ•°`__init__()`ä¸­ï¼Œå°†æ‰€éœ€çš„æ‰€æœ‰å±‚å®šä¹‰ä¸ºç±»å±æ€§ã€‚åƒ`nn.Linear`å’Œ`nn.Conv2d`è¿™æ ·çš„å›¾å±‚å¯¹è±¡æœ¬èº«å°±æ˜¯`nn.Module`å­ç±»ï¼Œå¹¶ä¸”åŒ…å«å¯å­¦ä¹ çš„å‚æ•°ï¼Œ è¿™æ ·æ‚¨å°±ä¸å¿…è‡ªå·±å®ä¾‹åŒ–åŸå§‹å¼ é‡ã€‚ `nn.Module` å°†ä¸ºæ‚¨è·Ÿè¸ªè¿™äº›å†…éƒ¨å‚æ•°ã€‚ è¯·å‚é˜… [æ–‡æ¡£](http://pytorch.org/docs/master/nn.html)ä»¥äº†è§£æœ‰å…³æ•°åä¸ªå†…ç½®å±‚çš„æ›´å¤šä¿¡æ¯ã€‚ **è­¦å‘Š**: ä¸è¦å¿˜è®°å…ˆè°ƒç”¨ `super().__init__()` ï¼\n",
    "\n",
    "3. åœ¨`forward()`æ–¹æ³•ä¸­ï¼Œå®šä¹‰ç½‘ç»œçš„*è¿æ¥æ€§*ã€‚ æ‚¨åº”è¯¥ä½¿ç”¨ __init__ ä¸­å®šä¹‰çš„å±æ€§ä½œä¸ºå‡½æ•°è°ƒç”¨ï¼Œä»¥å¼ é‡ä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºâ€œè½¬æ¢åçš„â€å¼ é‡ã€‚*ä¸è¦* åœ¨`forward()`ä¸­åˆ›å»ºå…·æœ‰å¯å­¦ä¹ å‚æ•°çš„ä»»ä½•æ–°å±‚ï¼æ‰€æœ‰è¿™äº›éƒ½å¿…é¡»åœ¨â€œ__init__â€ä¸­é¢„å…ˆå£°æ˜ã€‚\n",
    "\n",
    "å®šä¹‰æ¨¡å—å­ç±»åï¼Œæ‚¨å¯ä»¥å°†å…¶å®ä¾‹åŒ–ä¸ºå¯¹è±¡å¹¶è°ƒç”¨å®ƒ,å°±åƒPart IIä¸­çš„ NN å‰å‘å‡½æ•°ä¸€æ ·ã€‚\n",
    "\n",
    "### Module API:åŒå±‚ç½‘ç»œ\n",
    "ä¸‹é¢æ˜¯ä¸€ä¸ª 2 å±‚å…¨è¿æ¥ç½‘ç»œçš„å…·ä½“ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        # å°†å›¾å±‚å¯¹è±¡åˆ†é…ç»™ç±»å±æ€§\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # nn.init åŒ…å«ä¾¿æ·çš„åˆå§‹åŒ–æ–¹æ³•\n",
    "        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward å§‹ç»ˆå®šä¹‰è¿æ¥æ€§\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    input_size = 50\n",
    "    x = torch.zeros((64, input_size), dtype=dtype)  # å°æ‰¹é‡å¤§å° 64, ç‰¹å¾ç»´åº¦ 50\n",
    "    model = TwoLayerFC(input_size, 42, 10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # ä½ åº”è¯¥çœ‹åˆ° [64, 10]\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: ä¸‰å±‚å·ç§¯ç½‘ç»œ\n",
    "ç°åœ¨è½®åˆ°ä½ å®ç°ä¸€ä¸ª 3 å±‚ ConvNetï¼Œç„¶åæ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚ç½‘ç»œæ¶æ„åº”è¯¥ä¸Part IIç›¸ä¼¼:\n",
    "\n",
    "1. å…·æœ‰â€œchannel_1â€5x5 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼Œé›¶å¡«å……ä¸º 2\n",
    "2. ReLU\n",
    "3. å…·æœ‰â€œchannel_2â€ 3x3 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼Œé›¶å¡«å……ä¸º 1\n",
    "4. ReLU\n",
    "5. åˆ°â€œnum_classesâ€ç±»çš„å…¨è¿æ¥å±‚\n",
    "\n",
    "æ‚¨åº”è¯¥ä½¿ç”¨ Kaiming æ³•çº¿åˆå§‹åŒ–æ–¹æ³•æ¥åˆå§‹åŒ–æ¨¡å‹çš„æƒé‡çŸ©é˜µã€‚\n",
    "\n",
    "**æç¤º**: http://pytorch.org/docs/stable/nn.html#conv2d\n",
    "\n",
    "å®ç°ä¸‰å±‚ ConvNet å, `test_ThreeLayerConvNet` å‡½æ•°å°†è¿è¡Œæ‚¨çš„å®ç°; å®ƒåº”è¯¥æ‰“å°`(64, 10)`ä½œä¸ºè¾“å‡ºåˆ†æ•°çš„å½¢çŠ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„æ¶æ„è®¾ç½®ä¸‰å±‚ ConvNet æ‰€éœ€çš„å±‚                      #\n",
    "        ########################################################################\n",
    "        #*****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****         #\n",
    "        ########################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.constant_(self.conv1.bias, 0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        nn.init.constant_(self.conv2.bias, 0)\n",
    "        \n",
    "        self.fc = nn.Linear(channel_2*32*32, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        \n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: å®ç° 3 å±‚ ConvNet çš„å‰å‘åŠŸèƒ½ã€‚æ‚¨åº”è¯¥ä½¿ç”¨åœ¨ __init__ ä¸­å®šä¹‰çš„å±‚   #\n",
    "        # å¹¶åœ¨forward() ä¸­æŒ‡å®šè¿™äº›å±‚çš„è¿æ¥                                      #\n",
    "        ########################################################################\n",
    "        #*****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****         #\n",
    "        ########################################################################\n",
    "        \n",
    "        relu1 = F.relu(self.conv1(x))\n",
    "        relu2 = F.relu(self.conv2(relu1))\n",
    "        scores = self.fc(flatten(relu2))\n",
    "        \n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #\n",
    "        ########################################################################\n",
    "        return scores\n",
    "\n",
    "\n",
    "def test_ThreeLayerConvNet():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # å°æ‰¹é‡å¤§å° 64, å›¾ç‰‡å¤§å° [3, 32, 32]\n",
    "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # ä½ åº”è¯¥çœ‹åˆ° [64, 10]\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: æ£€æŸ¥å‡†ç¡®æ€§\n",
    "ç»™å®šéªŒè¯æˆ–æµ‹è¯•é›†ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ç¥ç»ç½‘ç»œçš„åˆ†ç±»å‡†ç¡®æ€§ã€‚\n",
    "\n",
    "è¿™ä¸ªç‰ˆæœ¬ä¸ç¬¬äºŒéƒ¨åˆ†çš„ç‰ˆæœ¬ç•¥æœ‰ä¸åŒã€‚æ‚¨ä¸å†æ‰‹åŠ¨ä¼ é€’å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # è½¬æ¢è®¾å¤‡ï¼Œä¾‹å¦‚GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: è®­ç»ƒå¾ªç¯\n",
    "æˆ‘ä»¬è¿˜ä½¿ç”¨äº†ç¨å¾®ä¸åŒçš„è®­ç»ƒå¾ªç¯, æˆ‘ä»¬ä¸æ˜¯è‡ªå·±æ›´æ–°æƒé‡å€¼ï¼Œè€Œæ˜¯ä½¿ç”¨`torch.optim`åŒ…ä¸­çš„ Optimizer å¯¹è±¡ï¼Œè¯¥å¯¹è±¡æŠ½è±¡äº†ä¼˜åŒ–ç®—æ³•çš„æ¦‚å¿µï¼Œå¹¶æä¾›äº†å¤§å¤šæ•°å¸¸ç”¨äºä¼˜åŒ–ç¥ç»ç½‘ç»œçš„ç®—æ³•çš„å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ PyTorch æ¨¡å— API åœ¨ CIFAR-10 ä¸Šè®­ç»ƒæ¨¡å‹ã€‚\n",
    "    \n",
    "    è¾“å…¥:\n",
    "    - model: æä¾›æ¨¡å‹è®­ç»ƒçš„ PyTorch Modelã€‚\n",
    "    - optimizer: æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ª Optimizer å¯¹è±¡æ¥è®­ç»ƒæ¨¡å‹ã€‚\n",
    "    - epochs: (å¯é€‰) ä¸€ä¸ª Python æ•´æ•°ï¼Œç»™å®šè¦è®­ç»ƒçš„æ¬¡æ•°\n",
    "    \n",
    "    è¿”å›: Nothing, ä½†åœ¨è®­ç»ƒæœŸé—´æ‰“å°æ¨¡å‹ç²¾åº¦ã€‚\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # å°†æ¨¡å‹å‚æ•°ç§»è‡³CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # å°†æ¨¡å‹ç½®äºè®­ç»ƒæ¨¡å¼\n",
    "            x = x.to(device=device, dtype=dtype)  # è½¬æ¢è®¾å¤‡ï¼Œä¾‹å¦‚GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # å°†ä¼˜åŒ–å™¨å°†æ›´æ–°çš„å˜é‡çš„æ‰€æœ‰æ¢¯åº¦å½’é›¶ã€‚\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # è¿™æ˜¯å‘åä¼ é€’ï¼šè®¡ç®—æ¨¡å‹æ¯ä¸ªå‚æ•°çš„æŸå¤±æ¢¯åº¦ã€‚\n",
    "            loss.backward()\n",
    "\n",
    "            # å®é™…ä¸Šä½¿ç”¨å‘åä¼ é€’è®¡ç®—çš„æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: è®­ç»ƒåŒå±‚ç½‘ç»œ\n",
    "ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½è¿è¡Œè®­ç»ƒå¾ªç¯äº†ã€‚ä¸Part IIç›¸åï¼Œæˆ‘ä»¬ä¸å†æ˜¾å¼åˆ†é…å‚æ•°å¼ é‡ã€‚\n",
    "\n",
    "åªéœ€å°†è¾“å…¥å¤§å°ã€éšè—å±‚å¤§å°å’Œç±»æ•°ï¼ˆå³è¾“å‡ºå¤§å°ï¼‰ä¼ é€’ç»™`TwoLayerFC`çš„æ„é€ å‡½æ•°å³å¯ã€‚\n",
    "\n",
    "æ‚¨è¿˜éœ€è¦å®šä¹‰ä¸€ä¸ªä¼˜åŒ–å™¨æ¥è·Ÿè¸ª`TwoLayerFC`å†…çš„æ‰€æœ‰å¯å­¦ä¹ å‚æ•°ã€‚\n",
    "\n",
    "æ‚¨ä¸éœ€è¦è°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†åœ¨è®­ç»ƒä¸€ä¸ª epoch åï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°æ¨¡å‹å‡†ç¡®ç‡é«˜äº 40%ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.2762\n",
      "Checking accuracy on validation set\n",
      "Got 119 / 1000 correct (11.90)\n",
      "\n",
      "Iteration 100, loss = 2.6811\n",
      "Checking accuracy on validation set\n",
      "Got 332 / 1000 correct (33.20)\n",
      "\n",
      "Iteration 200, loss = 1.9052\n",
      "Checking accuracy on validation set\n",
      "Got 381 / 1000 correct (38.10)\n",
      "\n",
      "Iteration 300, loss = 1.9003\n",
      "Checking accuracy on validation set\n",
      "Got 386 / 1000 correct (38.60)\n",
      "\n",
      "Iteration 400, loss = 1.8123\n",
      "Checking accuracy on validation set\n",
      "Got 422 / 1000 correct (42.20)\n",
      "\n",
      "Iteration 500, loss = 2.0043\n",
      "Checking accuracy on validation set\n",
      "Got 360 / 1000 correct (36.00)\n",
      "\n",
      "Iteration 600, loss = 1.8639\n",
      "Checking accuracy on validation set\n",
      "Got 442 / 1000 correct (44.20)\n",
      "\n",
      "Iteration 700, loss = 1.9156\n",
      "Checking accuracy on validation set\n",
      "Got 466 / 1000 correct (46.60)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: è®­ç»ƒä¸‰å±‚å·ç§¯ç½‘ç»œ\n",
    "æ‚¨ç°åœ¨åº”è¯¥ä½¿ç”¨æ¨¡å— API åœ¨ CIFAR ä¸Šè®­ç»ƒä¸‰å±‚ ConvNetã€‚è¿™çœ‹èµ·æ¥åº”è¯¥ä¸è®­ç»ƒä¸¤å±‚ç½‘ç»œéå¸¸ç›¸ä¼¼ï¼ä½ ä¸éœ€è¦è°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†è®­ç»ƒä¸€ä¸ª epoch ååº”è¯¥è¾¾åˆ° 45% ä»¥ä¸Šã€‚\n",
    "\n",
    "æ‚¨åº”è¯¥ä½¿ç”¨æ²¡æœ‰åŠ¨é‡çš„éšæœºæ¢¯åº¦ä¸‹é™æ¥è®­ç»ƒæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.8929\n",
      "Checking accuracy on validation set\n",
      "Got 144 / 1000 correct (14.40)\n",
      "\n",
      "Iteration 100, loss = 1.9717\n",
      "Checking accuracy on validation set\n",
      "Got 348 / 1000 correct (34.80)\n",
      "\n",
      "Iteration 200, loss = 1.8484\n",
      "Checking accuracy on validation set\n",
      "Got 394 / 1000 correct (39.40)\n",
      "\n",
      "Iteration 300, loss = 1.6329\n",
      "Checking accuracy on validation set\n",
      "Got 420 / 1000 correct (42.00)\n",
      "\n",
      "Iteration 400, loss = 1.8622\n",
      "Checking accuracy on validation set\n",
      "Got 466 / 1000 correct (46.60)\n",
      "\n",
      "Iteration 500, loss = 1.7899\n",
      "Checking accuracy on validation set\n",
      "Got 457 / 1000 correct (45.70)\n",
      "\n",
      "Iteration 600, loss = 1.5297\n",
      "Checking accuracy on validation set\n",
      "Got 476 / 1000 correct (47.60)\n",
      "\n",
      "Iteration 700, loss = 1.3070\n",
      "Checking accuracy on validation set\n",
      "Got 497 / 1000 correct (49.70)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "################################################################################\n",
    "# TODO: å®ä¾‹åŒ–æ‚¨çš„ ThreeLayerConvNet æ¨¡å‹å’Œç›¸åº”çš„ä¼˜åŒ–å™¨                          #\n",
    "################################################################################\n",
    "#*****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****                 #\n",
    "################################################################################\n",
    "\n",
    "model = ThreeLayerConvNet(3, channel_1, channel_2, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "################################################################################\n",
    "#                             END OF YOUR CODE                                 #\n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. PyTorch Sequential API\n",
    "\n",
    "Part III å¼•å…¥äº† PyTorch Module API, å®ƒå…è®¸æ‚¨å®šä¹‰ä»»æ„å¯å­¦ä¹ å±‚åŠå…¶è¿æ¥æ€§ã€‚\n",
    "\n",
    "å¯¹äºç®€å•æ¨¡å‹ï¼Œä¾‹å¦‚ä¸€å †å‰é¦ˆå±‚, ä½ è¿˜éœ€è¦å®Œæˆ3ä¸ªæ­¥éª¤: å­ç±» `nn.Module`, åœ¨`__init__`ä¸­å°†å±‚åˆ†é…ç»™ç±»å±æ€§ï¼Œå¹¶åœ¨`forward()`ä¸­é€å±‚è°ƒç”¨æ¯ä¸€å±‚ã€‚ \n",
    "\n",
    "æœ‰æ²¡æœ‰æ›´ä¾¿æ·çš„æ–¹æ³•å‘¢ï¼Ÿ\n",
    "\n",
    "å¹¸è¿çš„æ˜¯, PyTorch æä¾›äº†ä¸€ä¸ªåä¸º `nn.Sequential`çš„å®¹å™¨æ¨¡å—ï¼Œ, å®ƒå°†ä¸Šè¿°æ­¥éª¤åˆå¹¶ä¸ºä¸€ä¸ª. å®ƒä¸åƒ`nn.Module`é‚£ä¹ˆçµæ´»ï¼Œå› ä¸ºæ‚¨æ— æ³•æŒ‡å®šæ¯”å‰é¦ˆå †æ ˆæ›´å¤æ‚çš„æ‹“æ‰‘ï¼Œä½†å®ƒå¯¹äºè®¸å¤šç”¨ä¾‹æ¥è¯´å·²ç»è¶³å¤Ÿäº†ã€‚\n",
    "\n",
    "### Sequential API: åŒå±‚ç½‘ç»œ\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨`nn.Sequential`é‡å†™æˆ‘ä»¬çš„ä¸¤å±‚å…¨è¿æ¥ç½‘ç»œç¤ºä¾‹ï¼Œå¹¶ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„è®­ç»ƒå¾ªç¯æ¥è®­ç»ƒå®ƒã€‚\n",
    "\n",
    "åŒæ ·ï¼Œæ‚¨ä¸éœ€è¦åœ¨è¿™é‡Œè°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†ç»è¿‡ä¸€ä¸ª epoch çš„è®­ç»ƒåï¼Œæ‚¨åº”è¯¥è¾¾åˆ° 40% ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3243\n",
      "Checking accuracy on validation set\n",
      "Got 174 / 1000 correct (17.40)\n",
      "\n",
      "Iteration 100, loss = 1.8203\n",
      "Checking accuracy on validation set\n",
      "Got 390 / 1000 correct (39.00)\n",
      "\n",
      "Iteration 200, loss = 1.7088\n",
      "Checking accuracy on validation set\n",
      "Got 388 / 1000 correct (38.80)\n",
      "\n",
      "Iteration 300, loss = 1.6694\n",
      "Checking accuracy on validation set\n",
      "Got 406 / 1000 correct (40.60)\n",
      "\n",
      "Iteration 400, loss = 1.8396\n",
      "Checking accuracy on validation set\n",
      "Got 426 / 1000 correct (42.60)\n",
      "\n",
      "Iteration 500, loss = 1.9302\n",
      "Checking accuracy on validation set\n",
      "Got 422 / 1000 correct (42.20)\n",
      "\n",
      "Iteration 600, loss = 1.8641\n",
      "Checking accuracy on validation set\n",
      "Got 423 / 1000 correct (42.30)\n",
      "\n",
      "Iteration 700, loss = 1.5718\n",
      "Checking accuracy on validation set\n",
      "Got 446 / 1000 correct (44.60)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æˆ‘ä»¬éœ€è¦å°†`flatten`å‡½æ•°åŒ…è£…åœ¨æ¨¡å—ä¸­ï¼Œä»¥ä¾¿å°†å…¶å †å åœ¨ nn.Sequential ä¸­\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 10),\n",
    ")\n",
    "\n",
    "# æ‚¨å¯ä»¥åœ¨ optim.SGD ä¸­ä½¿ç”¨ Nesterov åŠ¨é‡\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API: ä¸‰å±‚å·ç§¯ç½‘ç»œ\n",
    "åœ¨è¿™é‡Œï¼Œæ‚¨åº”è¯¥ä½¿ç”¨`nn.Sequential`æ¥å®šä¹‰å’Œè®­ç»ƒä¸€ä¸ªä¸‰å±‚ ConvNetï¼Œå…¶æ¶æ„ä¸æˆ‘ä»¬åœ¨Part IIIä¸­ä½¿ç”¨çš„æ¶æ„ç›¸åŒï¼š\n",
    "\n",
    "1. å…·æœ‰ 32 ä¸ª 5x5 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦åç½®ï¼‰ï¼Œé›¶å¡«å……ä¸º 2\n",
    "2. ReLU\n",
    "3. å…·æœ‰ 16 ä¸ª 3x3 æ»¤æ³¢å™¨çš„å·ç§¯å±‚ï¼ˆå¸¦åç½®ï¼‰ï¼Œé›¶å¡«å……ä¸º 1\n",
    "4. ReLU\n",
    "5. å…¨è¿æ¥å±‚ï¼ˆå¸¦æœ‰åå·®ï¼‰è®¡ç®— 10 ä¸ªç±»åˆ«çš„åˆ†æ•°\n",
    "\n",
    "æ‚¨åº”è¯¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„`random_weight`å‡½æ•°åˆå§‹åŒ–æƒé‡çŸ©é˜µï¼Œå¹¶ä¸”åº”è¯¥ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„`zero_weight`å‡½æ•°åˆå§‹åŒ–åå·®å‘é‡ã€‚\n",
    "\n",
    "æ‚¨åº”è¯¥ä½¿ç”¨ Nesterov åŠ¨é‡ 0.9 çš„éšæœºæ¢¯åº¦ä¸‹é™æ¥ä¼˜åŒ–æ‚¨çš„æ¨¡å‹ã€‚\n",
    "\n",
    "åŒæ ·ï¼Œæ‚¨ä¸éœ€è¦è°ƒæ•´ä»»ä½•è¶…å‚æ•°ï¼Œä½†ç»è¿‡ä¸€è½®è®­ç»ƒåæ‚¨åº”è¯¥ä¼šçœ‹åˆ°å‡†ç¡®ç‡é«˜äº 55%ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal(shape):\n",
    "    \"\"\"\n",
    "    ä¸ºæƒé‡åˆ›å»ºéšæœºå¼ é‡ï¼›è®¾ç½® require_grad=True æ„å‘³ç€æˆ‘ä»¬è¦åœ¨å‘åä¼ é€’è¿‡ç¨‹ä¸­è®¡ç®—è¿™äº›å¼ é‡çš„æ¢¯åº¦ã€‚\n",
    "    æˆ‘ä»¬ä½¿ç”¨ Kaiming åˆå§‹åŒ–: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[1]  # ä¸ `random_weight()` ä¸åŒï¼Œpytorch ä¸­ nn.Linear çš„æƒé‡å½¢çŠ¶ä¸ºï¼š[out_feature, in_feature]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # è½¬æ¢æƒé‡ [out_channel, in_channel, kH, kW]\n",
    "    # randn æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒç”Ÿæˆå™¨ã€‚\n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def xavier_normal(shape):\n",
    "    \"\"\"\n",
    "    ä¸ºæƒé‡åˆ›å»ºéšæœºå¼ é‡ï¼›è®¾ç½® require_grad=True æ„å‘³ç€æˆ‘ä»¬è¦åœ¨å‘åä¼ é€’è¿‡ç¨‹ä¸­è®¡ç®—è¿™äº›å¼ é‡çš„æ¢¯åº¦ã€‚\n",
    "    æˆ‘ä»¬ä½¿ç”¨ Xavier åˆå§‹åŒ–: sqrt(2 / (fan_in + fan_out))\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[1]\n",
    "        fan_out = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # è½¬æ¢æƒé‡ [out_channel, in_channel, kH, kW]\n",
    "        fan_out = shape[0] * shape[2] * shape[3]\n",
    "    # randn æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒç”Ÿæˆå™¨ã€‚\n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / (fan_in + fan_out))\n",
    "    w.requires_grad = True\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.4132\n",
      "Checking accuracy on validation set\n",
      "Got 158 / 1000 correct (15.80)\n",
      "\n",
      "Iteration 100, loss = 1.6887\n",
      "Checking accuracy on validation set\n",
      "Got 429 / 1000 correct (42.90)\n",
      "\n",
      "Iteration 200, loss = 1.3527\n",
      "Checking accuracy on validation set\n",
      "Got 487 / 1000 correct (48.70)\n",
      "\n",
      "Iteration 300, loss = 1.4333\n",
      "Checking accuracy on validation set\n",
      "Got 489 / 1000 correct (48.90)\n",
      "\n",
      "Iteration 400, loss = 1.4937\n",
      "Checking accuracy on validation set\n",
      "Got 524 / 1000 correct (52.40)\n",
      "\n",
      "Iteration 500, loss = 1.2148\n",
      "Checking accuracy on validation set\n",
      "Got 528 / 1000 correct (52.80)\n",
      "\n",
      "Iteration 600, loss = 1.2533\n",
      "Checking accuracy on validation set\n",
      "Got 545 / 1000 correct (54.50)\n",
      "\n",
      "Iteration 700, loss = 1.1077\n",
      "Checking accuracy on validation set\n",
      "Got 572 / 1000 correct (57.20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "################################################################################\n",
    "# TODO:ä½¿ç”¨ Sequential API é‡å†™ç¬¬ä¸‰éƒ¨åˆ†ä¸­å¸¦æœ‰åå·®çš„ 3 å±‚ ConvNetã€‚               #                                                        #\n",
    "################################################################################\n",
    "#*****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****                 #\n",
    "################################################################################\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, channel_1, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2*32*32, 10),\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "# æƒé‡åˆå§‹åŒ–\n",
    "# å‚è€ƒ: http://pytorch.org/docs/stable/nn.html#torch.nn.Module.apply\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "#         m.weight.data = random_weight(m.weight.size())\n",
    "#         m.weight.data = kaiming_normal(m.weight.size())\n",
    "        m.weight.data = xavier_normal(m.weight.size())\n",
    "        m.bias.data = zero_weight(m.bias.size())\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "################################################################################\n",
    "#                            END OF YOUR CODE                                  #                           \n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 å¼€æ”¾å¼æŒ‘æˆ˜\n",
    "\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œæ‚¨å¯ä»¥åœ¨ CIFAR-10 ä¸Šè¯•éªŒæ‚¨æƒ³è¦çš„ä»»ä½• ConvNet æ¶æ„ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œæ‚¨çš„å·¥ä½œæ˜¯è¯•éªŒæ¶æ„ã€è¶…å‚æ•°ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œä»¥è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½¿å…¶åœ¨ 10 ä¸ª epoch å†…çš„ CIFAR-10 **éªŒè¯é›†** ä¸Šå®ç° **è‡³å°‘ 70%** çš„å‡†ç¡®åº¦ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä¸Šé¢çš„check_accuracy å’Œ train å‡½æ•°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨`nn.Module`æˆ–`nn.Sequential`APIã€‚\n",
    "\n",
    "æè¿°ä¸€ä¸‹ä½ åœ¨æœ¬ç¬”è®°æœ¬æœ«å°¾åšäº†ä»€ä¹ˆã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯æ¯ä¸ªç»„ä»¶çš„å®˜æ–¹ API æ–‡æ¡£ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼šæˆ‘ä»¬åœ¨`ç©ºé—´æ‰¹è§„èŒƒ`ç±»ä¸­æ‰€è¯´çš„åœ¨ PyTorch ä¸­ç§°ä¸º`BatchNorm2D`ã€‚\n",
    "\n",
    "* torch.nn åŒ…ä¸­çš„å±‚: http://pytorch.org/docs/stable/nn.html\n",
    "* æ¿€æ´»å‡½æ•°: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
    "* æŸå¤±å‡½æ•°: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "* Optimizersä¼˜åŒ–å™¨: http://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "\n",
    "### ä½ å¯ä»¥å°è¯•çš„äº‹æƒ…:\n",
    "- **è¿‡æ»¤å™¨å°ºå¯¸**: ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨äº†5x5ï¼›è¾ƒå°çš„è¿‡æ»¤å™¨æ˜¯å¦ä¼šæ›´æœ‰æ•ˆï¼Ÿ\n",
    "- **è¿‡æ»¤å™¨æ•°é‡**: ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨äº† 32 ä¸ªè¿‡æ»¤å™¨ã€‚æ˜¯è¶Šå¤šè¶Šå¥½è¿˜æ˜¯è¶Šå°‘è¶Šå¥½ï¼Ÿ\n",
    "- **æ± åŒ–ä¸è·¨æ­¥å·ç§¯**: æ‚¨ä½¿ç”¨æœ€å¤§æ± åŒ–è¿˜æ˜¯ä»…ä½¿ç”¨è·¨æ­¥å·ç§¯ï¼Ÿ\n",
    "- **æ‰¹é‡å½’ä¸€åŒ–**: å°è¯•åœ¨å·ç§¯å±‚ä¹‹åæ·»åŠ ç©ºé—´æ‰¹é‡å½’ä¸€åŒ–ï¼Œå¹¶åœ¨ä»¿å°„å±‚ä¹‹åæ·»åŠ æ™®é€šæ‰¹é‡å½’ä¸€åŒ–ã€‚æ‚¨çš„ç½‘ç»œè®­ç»ƒå¾—æ›´å¿«å—ï¼Ÿ\n",
    "- **ç½‘ç»œæ¶æ„**: ä¸Šé¢çš„ç½‘ç»œæœ‰ä¸¤å±‚å¯è®­ç»ƒå‚æ•°ã€‚ä½ èƒ½ç”¨æ·±åº¦ç½‘ç»œåšå¾—æ›´å¥½å—ï¼Ÿå€¼å¾—å°è¯•çš„è‰¯å¥½æ¶æ„åŒ…æ‹¬ï¼š\n",
    "    - [å·ç§¯-Relu-æ± åŒ–]xN -> [ä»¿å°„]xM -> [softmax or SVM]\n",
    "    - [å·ç§¯-Relu-å·ç§¯-Relu-æ± åŒ–]xN -> [ä»¿å°„]xM -> [softmax æˆ– SVM]\n",
    "    - [æ‰¹é‡å½’ä¸€åŒ–-Relu-å·ç§¯]xN -> [ä»¿å°„]xM -> [softmax æˆ– SVM]\n",
    "- **å…¨å±€å¹³å‡æ± **: ä¸è¦å±•å¹³ç„¶åæ‹¥æœ‰å¤šä¸ªä»¿å°„å±‚ï¼Œè€Œæ˜¯æ‰§è¡Œå·ç§¯ç›´åˆ°å›¾åƒå˜å°ï¼ˆ7x7 å·¦å³ï¼‰ï¼Œç„¶åæ‰§è¡Œå¹³å‡æ± åŒ–æ“ä½œä»¥è·å¾— 1x1 å›¾åƒå›¾ç‰‡ï¼ˆ1, 1 , Filter#ï¼‰ï¼Œç„¶åå°†å…¶é‡æ–°æ•´å½¢ä¸ºä¸€ä¸ª (Filter#) å‘é‡ã€‚ è¿™åœ¨è°·æ­Œçš„åˆå§‹ç½‘ç»œ[Google's Inception Network](https://arxiv.org/abs/1512.00567)ä¸­ä½¿ç”¨ (å…¶æ¶æ„è§è¡¨ 1).\n",
    "- **æ­£åˆ™åŒ–**: æ·»åŠ  l2 æƒé‡æ­£åˆ™åŒ–ï¼Œæˆ–è€…å¯èƒ½ä½¿ç”¨ Dropoutã€‚\n",
    "### å…³äºè®­ç»ƒçš„å°æç¤º\n",
    "å¯¹äºæ‚¨å°è¯•çš„æ¯ä¸ªç½‘ç»œæ¶æ„ï¼Œæ‚¨åº”è¯¥è°ƒæ•´å­¦ä¹ ç‡å’Œå…¶ä»–è¶…å‚æ•°ã€‚æ‰§è¡Œæ­¤æ“ä½œæ—¶ï¼Œéœ€è¦è®°ä½ä»¥ä¸‹é‡è¦äº‹é¡¹ï¼š\n",
    "\n",
    "- å¦‚æœå‚æ•°è¿è¡Œè‰¯å¥½ï¼Œæ‚¨åº”è¯¥ä¼šåœ¨å‡ ç™¾æ¬¡è¿­ä»£å†…çœ‹åˆ°æ”¹è¿›\n",
    "- è¯·è®°ä½è¶…å‚æ•°è°ƒæ•´çš„ä»ç²—åˆ°ç»†çš„æ–¹æ³•ï¼šé¦–å…ˆæµ‹è¯•å¤§é‡çš„è¶…å‚æ•°ï¼Œè¿›è¡Œå‡ æ¬¡è®­ç»ƒè¿­ä»£ï¼Œä»¥æ‰¾åˆ°æœ‰æ•ˆçš„å‚æ•°ç»„åˆã€‚\n",
    "- ä¸€æ—¦æ‰¾åˆ°ä¸€äº›ä¼¼ä¹æœ‰æ•ˆçš„å‚æ•°é›†ï¼Œå°±å¯ä»¥å›´ç»•è¿™äº›å‚æ•°è¿›è¡Œæ›´ç²¾ç»†çš„æœç´¢ã€‚æ‚¨å¯èƒ½éœ€è¦è®­ç»ƒæ›´å¤šæ¬¡æ•°ã€‚\n",
    "- æ‚¨åº”è¯¥ä½¿ç”¨éªŒè¯é›†è¿›è¡Œè¶…å‚æ•°æœç´¢ï¼Œå¹¶ä¿å­˜æµ‹è¯•é›†ï¼Œä»¥ä¾¿æ ¹æ®éªŒè¯é›†é€‰æ‹©çš„æœ€ä½³å‚æ•°è¯„ä¼°æ‚¨çš„æ¶æ„ã€‚\n",
    "\n",
    "### æ”¹è¿›ã€æé«˜ï¼\n",
    "å¦‚æœæ‚¨å–œæ¬¢æ¢ç´¢ï¼Œæ‚¨å¯ä»¥å®æ–½è®¸å¤šå…¶ä»–åŠŸèƒ½æ¥å°è¯•æé«˜æ‚¨çš„è¡¨ç°ã€‚ **ä¸éœ€è¦**å®ç°å…¶ä¸­ä»»ä½•ä¸€ä¸ªï¼Œä½†å¦‚æœæ‚¨æœ‰æ—¶é—´ï¼Œè¯·ä¸è¦é”™è¿‡å…¶ä¸­çš„ä¹è¶£ï¼\n",
    "\n",
    "- æ›¿ä»£ä¼˜åŒ–å™¨ï¼šä½ å¯ä»¥å°è¯• Adamã€Adagradã€RMSprop ç­‰ã€‚\n",
    "- æ›¿ä»£æ¿€æ´»å‡½æ•°ï¼Œä¾‹å¦‚leaky ReLUã€å‚æ•°åŒ–ReLUã€ELU æˆ–MaxOutã€‚\n",
    "- Modelæ•´åˆ\n",
    "- æ•°æ®å¢å¼º\n",
    "- æ–°æ¶æ„\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) å…¶ä¸­å‰ä¸€å±‚çš„è¾“å…¥è¢«æ·»åŠ åˆ°è¾“å‡ºä¸­ã€‚\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) å…¶ä¸­å‰ä¸€å±‚çš„è¾“å…¥è¿æ¥åœ¨ä¸€èµ·ã€‚\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "### äº«å—æ„‰å¿«ã€å¿«ä¹çš„è®­ç»ƒ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.4207\n",
      "Checking accuracy on validation set\n",
      "Got 105 / 1000 correct (10.50)\n",
      "\n",
      "Iteration 0, loss = 0.8765\n",
      "Checking accuracy on validation set\n",
      "Got 628 / 1000 correct (62.80)\n",
      "\n",
      "Iteration 0, loss = 0.7449\n",
      "Checking accuracy on validation set\n",
      "Got 693 / 1000 correct (69.30)\n",
      "\n",
      "Iteration 0, loss = 0.6328\n",
      "Checking accuracy on validation set\n",
      "Got 702 / 1000 correct (70.20)\n",
      "\n",
      "Iteration 0, loss = 0.6688\n",
      "Checking accuracy on validation set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "\n",
      "Iteration 0, loss = 0.5392\n",
      "Checking accuracy on validation set\n",
      "Got 754 / 1000 correct (75.40)\n",
      "\n",
      "Iteration 0, loss = 0.6220\n",
      "Checking accuracy on validation set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "\n",
      "Iteration 0, loss = 0.4938\n",
      "Checking accuracy on validation set\n",
      "Got 760 / 1000 correct (76.00)\n",
      "\n",
      "Iteration 0, loss = 0.4196\n",
      "Checking accuracy on validation set\n",
      "Got 770 / 1000 correct (77.00)\n",
      "\n",
      "Iteration 0, loss = 0.6582\n",
      "Checking accuracy on validation set\n",
      "Got 748 / 1000 correct (74.80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #         \n",
    "#  ä½¿ç”¨ä»»ä½•æ¶æ„ã€ä¼˜åŒ–å™¨å’Œè¶…å‚æ•°è¿›è¡Œå®éªŒã€‚                                        #\n",
    "#  åœ¨ 10 ä¸ªå‘¨æœŸå†…çš„â€œéªŒè¯é›†â€ä¸Šå®ç°è‡³å°‘ 70% çš„å‡†ç¡®ç‡ã€‚                             #\n",
    "#  è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ check_accuracy å‡½æ•°å¯¹æµ‹è¯•é›†æˆ–éªŒè¯é›†è¿›è¡Œè¯„ä¼°                 #\n",
    "#  æ–¹æ³•æ˜¯å°† loader_test æˆ– loader_val ä½œä¸ºç¬¬äºŒä¸ªå‚æ•°ä¼ é€’ç»™ check_accuracyã€‚      #\n",
    "#  åœ¨å®Œæˆæ¶æ„å’Œè¶…å‚æ•°è°ƒæ•´ä¹‹å‰ï¼Œä¸åº”è§¦æ‘¸æµ‹è¯•é›†                                    # \n",
    "#  å¹¶ä¸”ä»…åœ¨æœ€åè¿è¡Œæµ‹è¯•é›†ä¸€æ¬¡ä»¥æŠ¥å‘Šæœ€ç»ˆå€¼ã€‚                                      #\n",
    "################################################################################\n",
    "#*****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****                 #\n",
    "################################################################################\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# 4å±‚å·ç§¯ç½‘ç»œ\n",
    "# (å·ç§¯ -> æ‰¹é‡å½’ä¸€åŒ– -> Relu -> maxæ± åŒ–) * 3 -> fc\n",
    "layer1 = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=5, padding=2),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "\n",
    "layer2 = nn.Sequential(\n",
    "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "\n",
    "layer3 = nn.Sequential(\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2)\n",
    ")\n",
    "\n",
    "fc = nn.Linear(64*4*4, 10)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    layer1,\n",
    "    layer2,\n",
    "    layer3,\n",
    "    Flatten(),\n",
    "    fc\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# æ¯ä¸ªæ—¶æœŸæ‰“å°è®­ç»ƒçŠ¶æ€ï¼šå°† print_every è®¾ç½®ä¸ºä¸€ä¸ªå¤§æ•°å­—\n",
    "print_every = 10000\n",
    "\n",
    "################################################################################\n",
    "#                                END OF YOUR CODE                              #                       \n",
    "################################################################################\n",
    "\n",
    "# æ‚¨åº”è¯¥è·å¾—è‡³å°‘ 70% çš„å‡†ç¡®ç‡\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æè¿°ä¸€ä¸‹ä½ åšäº†ä»€ä¹ˆ\n",
    "\n",
    "åœ¨ä¸‹é¢çš„å•å…ƒæ ¼ä¸­ï¼Œæ‚¨åº”è¯¥è§£é‡Šæ‚¨æ‰€åšçš„äº‹æƒ…ã€æ‚¨å®ç°çš„ä»»ä½•é™„åŠ åŠŸèƒ½å’Œ/æˆ–æ‚¨åœ¨è®­ç»ƒå’Œè¯„ä¼°ç½‘ç»œçš„è¿‡ç¨‹ä¸­åˆ¶ä½œçš„ä»»ä½•å›¾è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: æè¿°ä¸€ä¸‹ä½ åšäº†ä»€ä¹ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æµ‹è¯•é›†â€”â€”ä»…è¿è¡Œä¸€æ¬¡\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»å¾—åˆ°äº†æ»¡æ„çš„ç»“æœï¼Œæˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•æˆ‘ä»¬çš„æœ€ç»ˆæ¨¡å‹ï¼ˆæ‚¨åº”è¯¥å°†å…¶å­˜å‚¨åœ¨ best_model ä¸­ï¼‰ã€‚è€ƒè™‘ä¸€ä¸‹è¿™ä¸æ‚¨çš„éªŒè¯é›†å‡†ç¡®æ€§ç›¸æ¯”å¦‚ä½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 7331 / 10000 correct (73.31)\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
